{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMA 2: MODELO CLASIFICACIÓN CHURN\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a recuperar el dataset procesado resultante del notebook del tema 1 (`T1_preprocesamiento.ipynb`): `churn_processed.csv`.\n",
    "\n",
    "El dataset contiene información relativa a los clientes de una compañía telefónica con la columna \"target\" que indica si el cliente abandonó la compañía durante el mes siguiente. El objetivo es entrenar un modelo de clasificación que prediga la probabilidad de abandono de los clientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install kds\n",
    "#%pip install optuna\n",
    "#%pip install optuna-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kds.metrics import plot_cumulative_gain\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_get_auc(model):\n",
    "    \n",
    "    y_train_prob = model.predict_proba(X_train)\n",
    "    y_test_prob = model.predict_proba(X_test)\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y_train, y_train_prob[:, 1])\n",
    "    print(\"AUC train = \", round(auc(fpr, tpr), 2))\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_test_prob[:, 1])\n",
    "    print(\"AUC test = \", round(auc(fpr, tpr), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"churn_processed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"target\"]\n",
    "X = df.drop(columns=[\"target\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree =  DecisionTreeClassifier(max_depth=4, random_state = 0)\n",
    "\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_get_auc(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo tiene una capacidad predictiva muy alta. Además, obtenemos el mismo AUC en train y en test, por lo que no hay sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "plot_tree(tree, feature_names=X_train.columns, filled = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de hiperparámetros con optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos la librería Optuna para la optimización de hiperparámetros de un random forest. Esta realiza una búsqueda inteligente: en lugar de probar todas las combinaciones posibles, va tomando decisiones secuenciales sobre qué combinaciones probar (con un máximo de intentos especificados) en base a los resultados de las iteraciones anteriores.\n",
    "\n",
    "1. Función a optimizar: Se buscará maximizar el AUC\n",
    "\n",
    "   - Espacio de búsqueda de hiperparámetros a optimizar.\n",
    "   - Creación del modelo específico con los hiperparámetros sugeridos\n",
    "   - Entrenamiento + cálculo de métrica\n",
    "\n",
    "2. Creación del caso de estudio y especificación del nº de búsquedas a realizar.\n",
    "\n",
    "3. Una vez acabada la búsqueda: obtenemos mejores hiperparámetros, entrenamos el modelo final y lo evaluamos sobre los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Definir el espacio de búsqueda de hiperparámetros\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 50)\n",
    "\n",
    "    # Definir y entrenar el modelo con los hiperparámetros sugeridos\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular AUC obtenido en la iteración\n",
    "    y_pred_test = model.predict_proba(X_test)\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_pred_test[:, 1])\n",
    "    auc_test = auc(fpr, tpr)\n",
    "    \n",
    "    return auc_test\n",
    "\n",
    "# Crear un estudio Optuna y ejecutar la optimización\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)# desactivar logs para que quede más limpio\n",
    "study = optuna.create_study(direction='maximize') # queremos maximizar la métrica (auc)\n",
    "study.optimize(objective, n_trials=10) # se lanza la busqueda con 10 intentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params # mejores hiperparametros obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study, target_name='AUC test') # visualización de los intentos y el AUC obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe() # obtener dataframe con el detalle de los intentos realizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_opt = DecisionTreeClassifier(**study.best_params)\n",
    "\n",
    "tree_opt.fit(X_train, y_train)\n",
    "\n",
    "predict_and_get_auc(tree_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con el Random Forest optimizado con optuna. Una vez entrenado el modelo, lo guardaríamos en formato pickle y lo utilizaríamos para hacer predicciones sobre nuevos datos de clientes que queremos estimar si son propensos a darse de baja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tree_opt, open('modelo.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importancia de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df = pd.DataFrame({\"variable\": X.columns, \"importancia relativa\": tree_opt.feature_importances_}) \\\n",
    ".sort_values(by='importancia relativa', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=imp_df, x='importancia relativa', y='variable')\n",
    "plt.title('Importancia de las Variables')\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Características')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos fijamos en la importancia relativa, vemos que aquellas variables con mayor importancia se corresponden con algunas de las que vimos gráficamente tenían alta relación con el target en el notebook `T1_preprocesamiento.ipynb`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df, x = 'target', y = 'num_dt', errorbar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df, x = 'target', y = 'incidencia', errorbar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df, x = 'target', y = 'descuentos', errorbar=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva de ganancia acumulada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo devuelve probabilidades asignadas a cada cliente, lo que permite ordenar de mayor a menor probabilidad y tomar acciones solo sobre aquellos con probabilidad más alta. Muchas veces el volumen de clientes a accionar va a depender de presupuestos de negocio: por ejemplo, si solo hay presupuesto para llamar a 1000 clientes, se llamará a los 1000 con mayor probabilidad.\n",
    "\n",
    "Sin embargo, cuando no está muy claro dónde hacer el corte, este gráfico puede ayudar a tomar decisiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob_tree  = tree_opt.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_gain(y_test, y_test_prob_tree[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva de ganancia acumulada indica el % de verdaderos positivos detectados por el modelo si seleccionásemos al x% de mayor probabilidad.\n",
    "\n",
    "- Eje x: % acumulado de observaciones (de mayor a menor probabilidad)\n",
    "- Eje y: % acumulado de verdaderos positivos\n",
    "\n",
    "\n",
    "La curva \"Wizard\" sería la curva del modelo perfecto (aquel que separase perfectamente): hay que fijarse en la curva \"Model\"\n",
    "\n",
    "**En este caso la curva indica que tan solo contactando a los 3 primeros deciles (el 30% de clientes con mayor probabilidad dada por el modelo), conseguiríamos detectar más del 80% de los que se acaban dando de baja. Sin usar modelo, contactando a un 30% aleatorio detectarías solo un 30% de las bajas. Por tanto, el modelo te permite afinar contactando solo a aquellos clientes que estás más seguro que se van a dar de baja, y por tanto ahorrar costes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de nuevos datos y predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos un nuevo set de datos con los clientes en cartera actualizados a fecha de hoy y queremos obtener la probabilidad de que se den de baja. Este dataset ya ha sido preparado en un script previo, por lo que directamente leemos este dataset y aplicamos predicciones cargando el modelo entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('churn_new_data.csv')\n",
    "df_new.head() # queremos predecir la probabilidad de baja de estos nuevos clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = pickle.load(open('modelo.pkl', 'rb')) # cargamos el modelo entrenado previamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = modelo.predict_proba(df_new.drop('id', axis = 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['pred'] = preds # asignamos cada probabilidad al idcliente correspondiente para poder accionarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.sort_values(by='pred', ascending = False).head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CAROLINA_ILLERA_39446109M_ML",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
